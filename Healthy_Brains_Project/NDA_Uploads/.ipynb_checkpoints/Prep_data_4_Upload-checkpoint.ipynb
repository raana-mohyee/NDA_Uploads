{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program prepares the data collected for the Healthy Brains project for upload to the NIMH Data Archive (NDA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# load measures from project data dictionary\n",
    "measures = ['TEPS', 'MAP-SR', 'CESD', 'COPE', 'CAPE']\n",
    "dataDict = {m:pd.read_excel('dataPrep/HBP_NDA_DataDict.xlsx', sheet_name=m) for m in measures}\n",
    "\n",
    "# load pseudo-GUIDs\n",
    "pGUIDs = pd.read_excel('dataPrep/HBP_NDA_DataDict.xlsx', sheet_name='pseudo-GUIDs') \n",
    "\n",
    "# load collected data & sort by 'subnum'\n",
    "qltrcs_data = pd.read_csv('dataPrep/Healthy+Brains+Project+-+Qualtrics+Survey_April+23,+2020_09.22.csv', skiprows=[1, 2]).sort_values(by='subnum')\n",
    "intvw_data = None # update when we get the database, remember to sort by subnum\n",
    "rawData = pd.concat([qltrcs_data, intvw_data], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[description of Measure class and capabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an object for each measure with the following capabilities\n",
    "class Measure():\n",
    "    \n",
    "    name = None\n",
    "    NDA_vars = None\n",
    "    HBP_vars = None\n",
    "    varmatches = dict([]) \n",
    "    Data = None\n",
    "    \n",
    "    # matches the HBP and NDA vars in a dictionary\n",
    "    def matchVars(self):\n",
    "        HBP = list(self.HBP_vars)\n",
    "        matches = {v:self.NDA_vars.iloc[HBP.index(v)] for v in HBP}\n",
    "        return matches\n",
    "    \n",
    "    # initializes object instance & sets object variables\n",
    "    def __init__(self, name):\n",
    "        global dataDict\n",
    "        self.name = name\n",
    "        self.NDA_vars = dataDict[name]['NDA varname']\n",
    "        self.HBP_vars = dataDict[name]['HBP varname']\n",
    "        self.varmatches = self.matchVars()\n",
    "        self.Data = pd.DataFrame(columns=self.NDA_vars)\n",
    "        return None\n",
    "    \n",
    "    # retrieves and returns raw data for a given HBP variable\n",
    "    def getVarData(self, hbpv):\n",
    "        global rawData\n",
    "        d = rawData[hbpv]\n",
    "        return d\n",
    "    \n",
    "    # formats interview_date as closer to upload-ready format, calculates age in months & populates interview_age\n",
    "    def formatDateObjs(self, df):\n",
    "        # convert timestamps to datetime objects\n",
    "        df['interview_date'] = df['interview_date'].apply(lambda x: dt.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\"))\n",
    "        df['interview_age'] = df['interview_age'].apply(lambda x: dt.datetime.strptime(str(x), \"%m/%d/%Y\"))\n",
    "        # calculate age in months & insert in table\n",
    "        diffs = df['interview_date'].sub(df['interview_age'])\n",
    "        df['interview_age'] = diffs.apply(lambda d: round(d.days/30))\n",
    "        # reformat interview_date as MM/DD/YYYY -- this section seems inefficient, revisit later\n",
    "        df['interview_date'] = df['interview_date'].apply(lambda x: dt.datetime.strftime(x, \"%m/%d/%Y\"))\n",
    "        df['interview_date'] = df['interview_date'].apply(lambda x: dt.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    \n",
    "    # adds pseudo-GUIDs\n",
    "    def addpGUIDs(self, frupld):\n",
    "        global pGUIDs\n",
    "        for i, r in frupld.iterrows():\n",
    "            sid = r['src_subject_id']\n",
    "            pguid = pGUIDs.query(\"study_ids == @sid\")['pGUIDs'].iloc[0]\n",
    "            frupld.at[i, 'subjectkey'] = pguid\n",
    "    \n",
    "    # adds missing values where appropriate\n",
    "    def addMissing(self):  \n",
    "        global dataDict\n",
    "        placeholders = dataDict[self.name]['missing'].notnull()\n",
    "        for i, v in placeholders.iteritems():\n",
    "            if v == False:\n",
    "                continue\n",
    "            else:\n",
    "                ndav = dataDict[self.name].at[i, 'NDA varname']\n",
    "                mval = dataDict[self.name].at[i, 'missing']\n",
    "                self.Data[ndav].fillna(mval, inplace=True)\n",
    "    \n",
    "    # fills columnns of self.Data with raw data \n",
    "    def fillColumns(self):\n",
    "        for v in self.HBP_vars:\n",
    "            if isinstance(v, type(float(\"Nan\"))):\n",
    "                continue\n",
    "            else:\n",
    "                data = self.getVarData(v)\n",
    "                ndav = self.varmatches[v]\n",
    "                self.Data[ndav] = data\n",
    "        return None\n",
    "    \n",
    "    # recodes sex data as String data instead of Integers\n",
    "    def fixSexData(self):\n",
    "        self.Data['sex'].replace({1:'M', 2:'F'}, inplace=True)\n",
    "        \n",
    "    def prepDtypeDict(self):\n",
    "        global dataDict\n",
    "        types = {'GUID':str, 'String':str, 'Integer':int, 'Float':float}\n",
    "        dtypes = pd.Series(data=dataDict[self.name]['NDA data type'].to_numpy(), index=dataDict[self.name]['NDA varname'])\n",
    "        for i, v in dtypes.iteritems():\n",
    "            if v not in types.keys():\n",
    "                dtypes.loc[i] = None\n",
    "            else:    \n",
    "                dtypes.loc[i] = types[v]\n",
    "        return dtypes.to_dict()\n",
    "    \n",
    "    def setDataTypes(self):\n",
    "        d = self.prepDtypeDict()\n",
    "        for v in d.keys(): # \"for each NDA var\"\n",
    "            if d[v] == None:\n",
    "                continue\n",
    "            elif v == 'visit':\n",
    "                self.Data[v].replace(np.nan, \" \", inplace=True, regex=True)\n",
    "            else:\n",
    "                self.Data[v].astype(d[v])\n",
    "\n",
    "    # applies the methods defined above to produce df of almost-upload-ready data for measure\n",
    "    def prepData(self):\n",
    "        self.fillColumns()\n",
    "        self.formatDateObjs(self.Data) \n",
    "        self.addpGUIDs(self.Data)\n",
    "        self.addMissing()\n",
    "        self.fixSexData()\n",
    "        self.setDataTypes()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Testing my code with the TEPS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NDA varname</th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>sex</th>\n",
       "      <th>teps1</th>\n",
       "      <th>teps2</th>\n",
       "      <th>teps3</th>\n",
       "      <th>teps4</th>\n",
       "      <th>teps5</th>\n",
       "      <th>...</th>\n",
       "      <th>teps18</th>\n",
       "      <th>teps_af_ic</th>\n",
       "      <th>teps_cf_ic</th>\n",
       "      <th>teps_total_ic</th>\n",
       "      <th>tepc_acsi</th>\n",
       "      <th>teps_ap</th>\n",
       "      <th>teps_cp</th>\n",
       "      <th>visnum</th>\n",
       "      <th>visit</th>\n",
       "      <th>timept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDAR_INVG0H96HN3</td>\n",
       "      <td>10013</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>698</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDAR_INVH5B3AF0L</td>\n",
       "      <td>10014</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>698</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NDAR_INVW6BGU18M</td>\n",
       "      <td>10017</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>704</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDAR_INV17R0Z5L7</td>\n",
       "      <td>10025</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>702</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NDAR_INV6A044NGU</td>\n",
       "      <td>10029</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>700</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDAR_INV3C7NW8HX</td>\n",
       "      <td>10033</td>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>700</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NDAR_INVTXVAUVWW</td>\n",
       "      <td>10038</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>700</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDAR_INVE96TPXJP</td>\n",
       "      <td>10039</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>697</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NDAR_INVD3PTWJKW</td>\n",
       "      <td>10040</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>723</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NDAR_INVFDWK6A6E</td>\n",
       "      <td>10041</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>698</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NDAR_INVNH8KWFLL</td>\n",
       "      <td>10052</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>700</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NDAR_INVEXD68KRM</td>\n",
       "      <td>10055</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>702</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NDAR_INV5X2GD35A</td>\n",
       "      <td>10056</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>709</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NDAR_INVB56F5JTV</td>\n",
       "      <td>10058</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>708</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NDAR_INVR0E1GHRN</td>\n",
       "      <td>10060</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>706</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NDAR_INVYM273ENY</td>\n",
       "      <td>10065</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>703</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NDAR_INVKDZL1PGT</td>\n",
       "      <td>10075</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>704</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NDAR_INVK801BF0Z</td>\n",
       "      <td>10082</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>708</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NDA varname        subjectkey  src_subject_id interview_date  interview_age  \\\n",
       "2            NDAR_INVG0H96HN3           10013     2019-11-19            698   \n",
       "0            NDAR_INVH5B3AF0L           10014     2019-10-14            698   \n",
       "13           NDAR_INVW6BGU18M           10017     2020-02-22            704   \n",
       "1            NDAR_INV17R0Z5L7           10025     2019-10-30            702   \n",
       "7            NDAR_INV6A044NGU           10029     2020-01-25            700   \n",
       "3            NDAR_INV3C7NW8HX           10033     2019-12-07            700   \n",
       "6            NDAR_INVTXVAUVWW           10038     2020-01-22            700   \n",
       "4            NDAR_INVE96TPXJP           10039     2019-12-14            697   \n",
       "5            NDAR_INVD3PTWJKW           10040     2019-12-20            723   \n",
       "11           NDAR_INVFDWK6A6E           10041     2020-02-15            698   \n",
       "12           NDAR_INVNH8KWFLL           10052     2020-02-19            700   \n",
       "8            NDAR_INVEXD68KRM           10055     2020-01-27            702   \n",
       "16           NDAR_INV5X2GD35A           10056     2020-03-14            709   \n",
       "17           NDAR_INVB56F5JTV           10058     2020-03-16            708   \n",
       "9            NDAR_INVR0E1GHRN           10060     2020-02-08            706   \n",
       "10           NDAR_INVYM273ENY           10065     2020-02-12            703   \n",
       "15           NDAR_INVKDZL1PGT           10075     2020-03-13            704   \n",
       "14           NDAR_INVK801BF0Z           10082     2020-02-25            708   \n",
       "\n",
       "NDA varname sex  teps1  teps2  teps3  teps4  teps5  ...  teps18  teps_af_ic  \\\n",
       "2             M      2      4      5      5      6  ...       6         NaN   \n",
       "0             M      1      6      6      6      6  ...       6         NaN   \n",
       "13            F      5      6      6      4      4  ...       6         NaN   \n",
       "1             F      6      6      2      6      4  ...       6         NaN   \n",
       "7             M      4      6      6      6      2  ...       5         NaN   \n",
       "3             F      4      6      4      6      2  ...       6         NaN   \n",
       "6             F      5      6      6      6      4  ...       6         NaN   \n",
       "4             M      3      6      5      5      2  ...       5         NaN   \n",
       "5             M      4      5      5      5      4  ...       4         NaN   \n",
       "11            F      4      4      6      5      1  ...       5         NaN   \n",
       "12            F      4      6      6      6      3  ...       6         NaN   \n",
       "8             F      4      6      3      5      1  ...       5         NaN   \n",
       "16            M      2      4      4      4      2  ...       5         NaN   \n",
       "17            F      4      6      6      4      3  ...       6         NaN   \n",
       "9             F      3      6      6      3      6  ...       4         NaN   \n",
       "10            F      4      6      6      6      4  ...       6         NaN   \n",
       "15            F      4      6      6      6      2  ...       6         NaN   \n",
       "14            F      2      5      5      6      5  ...       5         NaN   \n",
       "\n",
       "NDA varname  teps_cf_ic  teps_total_ic  tepc_acsi  teps_ap  teps_cp  visnum  \\\n",
       "2                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "0                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "13                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "1                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "7                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "3                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "6                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "4                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "5                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "11                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "12                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "8                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "16                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "17                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "9                   NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "10                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "15                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "14                  NaN            NaN        NaN      NaN      NaN     NaN   \n",
       "\n",
       "NDA varname  visit  timept  \n",
       "2              NaN   999.0  \n",
       "0              NaN   999.0  \n",
       "13             NaN   999.0  \n",
       "1              NaN   999.0  \n",
       "7              NaN   999.0  \n",
       "3              NaN   999.0  \n",
       "6              NaN   999.0  \n",
       "4              NaN   999.0  \n",
       "5              NaN   999.0  \n",
       "11             NaN   999.0  \n",
       "12             NaN   999.0  \n",
       "8              NaN   999.0  \n",
       "16             NaN   999.0  \n",
       "17             NaN   999.0  \n",
       "9              NaN   999.0  \n",
       "10             NaN   999.0  \n",
       "15             NaN   999.0  \n",
       "14             NaN   999.0  \n",
       "\n",
       "[18 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEPS = Measure('TEPS')\n",
    "TEPS.prepData()\n",
    "TEPS.Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "subjectkey :  <class 'str'>\n",
      "<class 'str'>\n",
      "src_subject_id :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "interview_date :  <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "<class 'str'>\n",
      "interview_age :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "sex :  <class 'str'>\n",
      "<class 'str'>\n",
      "teps1 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps2 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps3 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps4 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps5 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps6 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps7 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps8 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps9 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps10 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps11 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps12 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps13 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps14 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps15 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps16 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps17 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps18 :  <class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "teps_af_ic :  <class 'float'>\n",
      "<class 'str'>\n",
      "teps_cf_ic :  <class 'float'>\n",
      "<class 'str'>\n",
      "teps_total_ic :  <class 'float'>\n",
      "<class 'str'>\n",
      "tepc_acsi :  <class 'float'>\n",
      "<class 'str'>\n",
      "teps_ap :  <class 'float'>\n",
      "<class 'str'>\n",
      "teps_cp :  <class 'float'>\n",
      "<class 'str'>\n",
      "visnum :  <class 'float'>\n",
      "<class 'str'>\n",
      "visit :  <class 'float'>\n",
      "<class 'str'>\n",
      "timept :  <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "for v in TEPS.Data.columns:\n",
    "    print(type(v))\n",
    "    print(v, \": \", type(TEPS.Data[v][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THINGS LEFT TO DO\n",
    "1. [DONE] convert interview_age to age in months\n",
    "2. [DONE] add missing values where necessary\n",
    "3. [DONE] add pseudo-GUIDs\n",
    "4. [DONE] change sex data from 1s & 2s to Ms & Fs\n",
    "5. set data types for each variable according to codebook\n",
    "6. remove vars for which we don't collect data & aren't required (place this before populating sheet if possible)\n",
    "\n",
    "In writing to CSV remember to set index=False so that it doesn't write the index column.\n",
    "\n",
    "\n",
    "AFTER WRITING TO CSV:\n",
    "1. reformat interview_date to MM/DD/YYYY in MS Excel -- first try upload with dates saved as string data and see what happens\n",
    "2. add first row with label to spreadsheet\n",
    "3. make sure everything looks good\n",
    "\n",
    "NOTES::\n",
    "\n",
    "I still think I can reformat the code to include a dataCleaner class. It could take in the measure.forUpload df, make all the changes, and then return it. Meaning that we will need to set measure.forUpload = dataCleaner.mainFunc(measure)\n",
    "\n",
    "since there are a handful of data points that copy across measures for each subject, maybe we consider defining a subject class as well, so that we only have to calculate and populate that data once?   \n",
    "\n",
    "https://nda.nih.gov/vt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[applying to measures in bulk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventually, we want this cell, but not right now\n",
    "Measures = {m:Measure(m) for m in measures}\n",
    "\n",
    "for M in Measures.values():\n",
    "    M.fillColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner():\n",
    "    \n",
    "    self.measure = None\n",
    "    self.df = None\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        self.measure = m\n",
    "        self.df = m.Data\n",
    "        return None\n",
    "    \n",
    "    def addMissing(self): # KEEP IN MEASURE CLASS\n",
    "        \n",
    "    def calcAge(self): \n",
    "        \n",
    "    def formatIntvwDate(self):\n",
    "        \n",
    "    def sexData2str(self):\n",
    "        \n",
    "    def cleanData(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[['A', np.dtype(float)], ['B', np.dtype(int)], ['C', np.dtype(str)]], columns=['letters', 'dtypes'])\n",
    "df2 = pd.DataFrame(data=[['A', float], ['B', int], ['C', str]], columns=['letters', 'dtypes'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to set data types that I haven't completely worked out yet\n",
    "\n",
    "def prepDtypeDict(self):\n",
    "    global dataDict\n",
    "    types = {'GUID':str, 'String':str, 'Integer':int, 'Float':float}\n",
    "    dtypes = pd.Series(data=dataDict[self.name]['NDA data type'].to_numpy(), index=dataDict[self.name]['NDA varname'])\n",
    "    for i, r in dtypes.iteritems():\n",
    "        if r[0] not in types.keys():\n",
    "            continue\n",
    "        else:    \n",
    "            dtypes.loc[i][0] = types[dataDict[i][0]]\n",
    "    return dtypes.to_dict()\n",
    "    \n",
    "def setDataTypes(self):\n",
    "    d = self.prepDtypeDict()\n",
    "    for v in self.forUpload.columns: # for each NDA var\n",
    "        if v not in d.keys():\n",
    "            continue\n",
    "        else:\n",
    "            self.forUpload[v].astype(d[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.at[2, 'dtypes']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
